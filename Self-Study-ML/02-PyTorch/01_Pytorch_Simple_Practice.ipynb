{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고 사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[kaggle-MNIST](https://www.kaggle.com/vincentlefoulon/pytorch-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teddylee/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/teddylee/miniconda3/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basic Functions and Usages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0842e-19, -2.0566e+10,  8.5920e+09,  7.0065e-45],\n",
       "        [ 0.0000e+00,  3.5285e-33,  4.5779e-41,  3.5285e-33,  4.5779e-41],\n",
       "        [ 3.5522e-33,  4.5559e-41,  3.5522e-33,  4.5779e-41,  3.5522e-33]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct uninitialize tensor\n",
    "x = torch.empty(3, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check tensor size\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4295,  0.9393,  1.2178,  0.6311, -1.8682],\n",
       "        [ 0.4992, -0.6476,  1.1434, -0.6581,  0.0639],\n",
       "        [-0.2660, -0.1764, -0.4660,  1.2395, -0.0004]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate random tensors\n",
    "y = torch.randn(3, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# zeros and ones\n",
    "print(torch.zeros(3, 5))\n",
    "print(torch.ones(3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4295e+00,  9.3930e-01, -2.0566e+10,  8.5920e+09, -1.8682e+00],\n",
       "        [ 4.9920e-01, -6.4764e-01,  1.1434e+00, -6.5813e-01,  6.3866e-02],\n",
       "        [-2.6595e-01, -1.7638e-01, -4.6601e-01,  1.2395e+00, -4.0541e-04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add\n",
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4295,  0.9393,  1.2178,  0.6311, -1.8682],\n",
       "        [ 0.4992, -0.6476,  1.1434, -0.6581,  0.0639],\n",
       "        [-0.2660, -0.1764, -0.4660,  1.2395, -0.0004]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place addition\n",
    "x = torch.zeros(3, 5)\n",
    "x.add_(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract\n",
    "torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0436e+00, 8.8229e-01, 1.4831e+00, 3.9826e-01, 3.4902e+00],\n",
       "        [2.4920e-01, 4.1944e-01, 1.3073e+00, 4.3313e-01, 4.0788e-03],\n",
       "        [7.0731e-02, 3.1111e-02, 2.1717e-01, 1.5363e+00, 1.6436e-07]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply\n",
    "torch.mul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# division\n",
    "torch.div(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out parameter\n",
    "zero = torch.zeros(3, 5)\n",
    "one = torch.ones(3, 5)\n",
    "result = torch.empty(3, 5)\n",
    "torch.add(zero, one, out=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# use torch.view\n",
    "x = torch.ones(3, 5)\n",
    "print(x.size())\n",
    "x = x.view(5, 3)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.random.randn(3, 3)\n",
    "np_array.shape, type(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Tensor)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.from_numpy()\n",
    "torch_array = torch.from_numpy(np_array)\n",
    "torch_array.size(), type(torch_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.numpy()\n",
    "to_numpy_array = torch_array.numpy()\n",
    "to_numpy_array.shape, type(to_numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.datasets.MNIST\n",
    "torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.MNIST outputs a set of PIL images\n",
    "# We transform them to tensors\n",
    "MNIST_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "])\n",
    "\n",
    "# Load and transform data\n",
    "trainset = datasets.MNIST('/tmp', train=True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.MNIST('/tmp', train=False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(features), Label(labels) loading through iteration\n",
    "img, lbl = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size(), lbl.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision\n",
    "\n",
    "def visualize(image):\n",
    "    im = torchvision.utils.make_grid(image)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(img[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters here\n",
    "input_size = 28*28\n",
    "hidden_1_size = 128\n",
    "hidden_2_size = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "training_epoch = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network (Model Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "model_sequence = OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_1_size)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_1_size, hidden_2_size)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(hidden_2_size, output_size)),\n",
    "    ('softmax', nn.Softmax(dim=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(model_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.2956738233566285\n",
      "epoch: 0, loss: 2.2634285259246827\n",
      "epoch: 0, loss: 2.126222529411316\n",
      "epoch: 0, loss: 1.9458885240554809\n",
      "epoch: 0, loss: 1.8158244919776916\n",
      "epoch: 0, loss: 1.7266433215141297\n",
      "epoch: 0, loss: 1.6785507035255431\n",
      "epoch: 0, loss: 1.6476908349990844\n",
      "epoch: 0, loss: 1.6150638198852538\n",
      "epoch: 0, loss: 1.595977761745453\n",
      "epoch: 0, loss: 1.5894164228439331\n",
      "epoch: 0, loss: 1.5833081746101378\n",
      "epoch: 0, loss: 1.5858566403388976\n",
      "epoch: 0, loss: 1.5770608925819396\n",
      "epoch: 0, loss: 1.5750331377983093\n",
      "epoch: 0, loss: 1.5662693929672242\n",
      "epoch: 0, loss: 1.5574766206741333\n",
      "epoch: 0, loss: 1.5587181234359742\n",
      "epoch: 1, loss: 1.5572782039642334\n",
      "epoch: 1, loss: 1.5531983757019043\n",
      "epoch: 1, loss: 1.5566648745536804\n",
      "epoch: 1, loss: 1.558462052345276\n",
      "epoch: 1, loss: 1.550595724582672\n",
      "epoch: 1, loss: 1.5468142676353454\n",
      "epoch: 1, loss: 1.548676724433899\n",
      "epoch: 1, loss: 1.5500653338432313\n",
      "epoch: 1, loss: 1.5432995986938476\n",
      "epoch: 1, loss: 1.5403948664665221\n",
      "epoch: 1, loss: 1.5389266109466553\n",
      "epoch: 1, loss: 1.546637682914734\n",
      "epoch: 1, loss: 1.5376596236228943\n",
      "epoch: 1, loss: 1.5417435932159425\n",
      "epoch: 1, loss: 1.528404839038849\n",
      "epoch: 1, loss: 1.5458406853675841\n",
      "epoch: 1, loss: 1.5471224236488341\n",
      "epoch: 1, loss: 1.5434219622612\n",
      "epoch: 2, loss: 1.535258002281189\n",
      "epoch: 2, loss: 1.523565399646759\n",
      "epoch: 2, loss: 1.5361124062538147\n",
      "epoch: 2, loss: 1.5340202403068544\n",
      "epoch: 2, loss: 1.5335375380516052\n",
      "epoch: 2, loss: 1.5270027947425842\n",
      "epoch: 2, loss: 1.5271691632270814\n",
      "epoch: 2, loss: 1.5195678615570067\n",
      "epoch: 2, loss: 1.5260499787330628\n",
      "epoch: 2, loss: 1.527957887649536\n",
      "epoch: 2, loss: 1.523062562942505\n",
      "epoch: 2, loss: 1.528022162914276\n",
      "epoch: 2, loss: 1.520134825706482\n",
      "epoch: 2, loss: 1.5208773827552795\n",
      "epoch: 2, loss: 1.5267586779594422\n",
      "epoch: 2, loss: 1.5265515041351319\n",
      "epoch: 2, loss: 1.5250012922286986\n",
      "epoch: 2, loss: 1.5276229429244994\n"
     ]
    }
   ],
   "source": [
    "print_every = 50\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    cnt = 0\n",
    "    running_loss = 0\n",
    "    for image, label in iter(trainloader):\n",
    "        cnt += 1\n",
    "        # resize images to 784 from (28, 28) - flatten\n",
    "        image.resize_(image.size()[0], 28*28)\n",
    "        \n",
    "        # zero to all gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # train inputs\n",
    "        output = model(image)\n",
    "\n",
    "        # calculate losses\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if cnt % print_every == 0:\n",
    "            print(\"epoch: {}, loss: {}\".format(epoch, running_loss / print_every))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images.resize_(images.size()[0], 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
